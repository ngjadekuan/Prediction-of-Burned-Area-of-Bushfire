{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# FIT5149 S1 2020 Assessment 1: Bushfire Analysis using Meteorological Data\n\n\nStudent information\n- Family Name: Ng \n- Given Name: Jade Kuan\n- Student ID: 25510487\n- Student email:jkng11@student.monash.edu\n\nProgramming Language: R 3.6.1 in Jupyter Notebook\n\nR Libraries used:\n- psych\n- ggplot2\n- reshape2\n- lattice\n- dummies\n- caret\n- e1071\n- cowplot\n- bestNormalize\n- leaps\n- purrr\n- simEd\n- dplyr\n- caTools\n- Metrics\n- xgboost"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Table of Contents\n\n[1. Introduction](#sec_1)\n\n\n\n[2.Data Exploration](#sec_2)\n\n[3.Model Development](#sec_3)\n\n[4.Model Comparison](#sec_4)\n\n[5.Variable Identification and Explanation](#sec_5)\n\n[6.Conclusion](#sec_6)\n\n[7.References](#sec_7)"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 1. Introduction <a class=\"anchor\" id=\"sec_1\"></a>"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "This notebook includes results of the data analysis performed on a set of forest fires data that is obtained from a UCI website. The purpose of the data analysis is to build models from the data that can be used to predict the burned area using collected attributes. \n\nThe second section of the notebook shows the exploratory data analysis (EDA) performed to explore and understand the data. It looks at each attribute (variables) in the data to understand the nature and distribution of the attribute values. It also examines the correlation between the variables through visual analysis. A summary at the end highlights the key findings of the EDA.\n\nThe third section shows the development of the models namely linear regression, XGBoost and XGBoost Lasso. It details the process used to transform and build the model. During the transformation phase, outliers are removed and variables are normalised prior to building the model. After building the models,the final models are then presented along with an analysis and interpretation of the model. This section concludes with the results of using the models to predict burned area.\n\nThe fourth section provides comparisons of the performance of the models developed. This gives an indication as to which model built performs best with the forest fires data. Statistical methods such as root mean square error (RMSE) and mean squared error(MSE) are used to compare the performances of the models.\n\nThe fifth section looks into variable identification and explanation. In this subsection, important variables which affects the model selected and its performance are explained in greater details.\n\n\n\n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Load the libraries used in the notebook"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "library(psych) # for statistics \nlibrary(ggplot2) # used for visualisation\nlibrary(reshape2) # give new shape to array without changing its data\nlibrary(lattice) # used for data visualisation\nlibrary(dummies) # used for one hot encoding \nlibrary(caret) # machine learning library\nlibrary(e1071) # to find skewness of data\nlibrary(cowplot) # used to display visualisation side by side \nlibrary(bestNormalize) # used to normalise data\nlibrary(leaps) # used for computing best subsets regression\nlibrary(purrr) # used for map function\nlibrary(simEd) # for seed function \nlibrary(dplyr) # used for data manipulation\nlibrary(caTools) # used to split data into train and test\nlibrary(Metrics) # library to measure MSE\nlibrary(xgboost) # to use xgboost algorithm",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "## 2. Data Exploration<a class=\"anchor\" id=\"sec_2\"></a>"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "For this subsection, we are exploring the relationship between the predictor and response variables in the forest fire dataset with correlation analysis. The distributions of each of the variables are also investigated to determine whether transformation of the variables are required. Through this, we are able to get some basic intuition as to which variables are important.  "
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### 2.1 Overview of the Bushfire Dataset"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Loading the bushfire dataset\nfire_data <- read.csv(\"forestfires.csv\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "cat(\"The bushfire dataset has\", dim(fire_data)[1], \"observation records, each with\", dim(fire_data)[2],\n    \"attributes.\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "cat(\"The structure of the bushfire data is:\\n\\n\")\nstr(fire_data)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "From the data above, we can see that there are different type of variables such as integer, factor and number variables. \nInteger variables consist of X,Y and RH. \nFactor variables consist of month and day which need to be transformed to dummy variables to allow easy comparison.\nNumber variables consists of FFMC, DMC, DC, ISI, temp, wind, rain and area.\nHere, the details of each property will be explained:\n\n- **X**: x-axis spatial coordinate within the Montesinho park map: 1 to 9\n- **Y**: y-axis spatial coordinate within the Montesinho park map: 2 to 9\n- **month**: month of the year: \"jan\" to \"dec\" \n- **day**: day of the week: \"mon\" to \"sun\"\n- **FFMC**: FFMC index from the FWI system: 18.7 to 96.20\n- **DMC**: DMC index from the FWI system: 1.1 to 291.3 \n- **DC**: DC index from the FWI system: 7.9 to 860.6 \n- **ISI**: ISI index from the FWI system: 0.0 to 56.10\n- **temp**: temperature in Celsius degrees: 2.2 to 33.30\n-  **RH**: relative humidity in %: 15.0 to 100\n- **wind**: wind speed in km/h: 0.40 to 9.40 \n- **rain**: outside rain in mm/m2 : 0.0 to 6.4 \n- **area**: the burned area of the forest (in ha): 0.00 to 1090.84 \n\nThe details of the property are described in [Cortez and Morais, 2007]. "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "cat(\"The descriptive statistics of the variables in the dataset are: \\n\")\nsummary(fire_data)\n\ncat(\"The advanced descriptive statistics of the variables in the dataset are:\\n  \")\nround(describe(fire_data), 3)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Summary of Attributes:\n\n\n\nThe following table identifies which attributes are numerical and whether they are continuous or discrete, and which\nare categorical and whether they are nominal or ordinal. In addition, it includes some initial observations about the ranges and \ncommon values of the attributes.\n\n|Attribute  |Type       |Sub-type  |Comments                                                                              |\n|-----------|-----------|----------|--------------------------------------------------------------------------------------|\n|X          |Numerical  |Discrete   |value ranges from 1 to 9.|\n|Y          |Numerical  |Discrete   |value ranges from 2 to 9.|\n|month      |Categorical|Ordinal  |August and September have higher records of bushfire compared to other months.|\n|day        |Categorical |Ordinal  |Sunday has the highest record of bushfire compared to other days.|\n|Fine Fuel Moisture Code (FFMC)|Numerical |Continuous  |values range from 18.7 to 96.2. Probably has outliers - especially for the low values.|\n|Duff Moisture Code (DMC)          |Numerical |Continuous  |values range from 1.1 to 291.3. Probably has extreme outliers - especially for the low values.|\n|Drought Code (DC)          |Numerical |Continuous  |values range from 7.9 to 860.6. Probably has extreme outliers - especially for the low values.|\n|Initial Spread Index (ISI)        |Numerical  |Continuous|values range from 0 to 56.1. Probably has outliers - especially for the high values.|\n|Outside Temperature (Temp)       |Numerical  |Continuous|values range from 2.20 to 33.30 celcius. Average temperature is around 18.89 celcius.|\n|Outside Relative Humidity (RH)          |Numerical |Discrete  |values range from 15 to 100. Probably has outliers for high values.|\n|Outside Wind Speed (Wind)       |Numerical |Continuous  |values range from 0.4 to 9.4.|\n|Outside Rain (Rain)       |Numerical |Continuous  |values range from  0 to 6.4. Probably has outliers for high values.|\n|Total Burned Area (Area)       |Numerical |Continuous  |values range from 0 to 1090.84.Probably has outliers for high values. |"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### 2.2 Investigate distribution of each variable"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Below we are generating boxplots for numerical variables to view their distribution."
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "#plot size\noptions(repr.plot.width=9, repr.plot.height=8)\n#convert fire_data excluding x,y, month and day with several measurement columns into a data frame in this canonical format\nmelt_data <- melt(as.data.frame(fire_data[,c(-1,-2,-3,-4)]))\n\n#plotting boxplots\nggplot(melt_data,aes(x = variable,y = value)) +\nfacet_wrap(~variable, scales=\"free\") +\ngeom_boxplot(fill = \"darkmagenta\", color = 'black') +\nscale_y_continuous(labels=function (n) {format(n, scientific=FALSE)}) +\nggtitle(\"Figure 1: Boxplot for numerical variables in Fire Data\")\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "- The boxplot above indicate that outliers for all 9 numerical variables.\n- FFMC, DC and temperature have outliers which are of lower values while the remaining have outliers of high values.\n\n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Below we are generating barchart and histogram for categorical and numerical variables respectively to view their distribution."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# rearranging the days and months based so that the x labels are populated in orderly manner for graph\n\nfire_data$month <- factor(fire_data$month, levels=c(\"jan\", \"feb\",\"mar\",\"apr\",\"may\",\"jun\",\"jul\",\"aug\",\"sep\",\"oct\",\"nov\",\"dec\"))\nfire_data$day <- factor(fire_data$day, levels = c(\"mon\",\"tue\",\"wed\",\"thu\",\"fri\",\"sat\",\"sun\"))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# plot size\npar(mfrow = c(3,2))\n# plotting bar chart for months\nplot(as.factor(fire_data$month),main=\"Bar Chart of Months\",col=\"darkmagenta\" )\n# plotting bar chart for days \nplot(as.factor(fire_data$day),main=\"Bar Chart of Days\",col=\"darkmagenta\")\n# plotting histogram for FMC\nhist(fire_data$FFMC,main=\"Histogram of Fine Fuel Moisture Code(FFMC)\",xlab=\"FFMC\",col=\"darkmagenta\")\n# plotting histogram for DMC\nhist(fire_data$DMC,main=\"Histogram of Duff Moisture Code(DMC)\",xlab=\"DMC\",col=\"darkmagenta\")\n# plotting histogram for DC\nhist(fire_data$DC,main=\"Histogram of Drought Code(DC)\",xlab=\"DC\",col=\"darkmagenta\")\n# plotting histogram for ISI\nhist(fire_data$ISI,main=\"Histogram of Initial Spread Index (ISI)\",xlab=\"ISI\",col=\"darkmagenta\")\n# plotting histogram for Temp\nhist(fire_data$temp,main=\"Histogram of Outside Temperature(Temp) in ◦C\",xlab=\"Temp\",col=\"darkmagenta\")\n# plotting histogram for RH\nhist(fire_data$RH,main=\"Histogram of Outside Relative Humidity (RH) in % \",xlab=\"RH\",col=\"darkmagenta\")\n# plotting histogram for Wind\nhist(fire_data$wind,main=\"Histogram of Outside Wind Speed (Wind) in km/h \",xlab=\"Wind\",col=\"darkmagenta\")\n# plotting histogram for Rain\nhist(fire_data$rain,main=\"Histogram of Outside Rain (Rain) in mm/m^2\",xlab=\"Rain\",col=\"darkmagenta\")\n# plotting histogram for Area\nhist(fire_data$area,main=\"Histogram of Total Burned Area (Area)in ha\",xlab=\"Area\",col=\"darkmagenta\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The graphs above indicate that:\n\n**For categorical variables**: \n- August and September are months that have the relatively highest bushfire occurence compared to other months.\n- Sundays is when there is the highest occurence of bushfire, followed by friday and saturday. \n\n**For non categorical variables**:\n- The histogram of ISI, DMC, RH, Wind are right skewed. \n- The histogram of FFMC and DC are left skewed.\n- The histogram of Temp is normally distributed.\n- The histogram of Rain and Area are highly skewed towards 0.0 indicating the need to perform logarithm transformation on both these variables to make the pattern in the data more interpretable.\n\nWe can see that the range differs for most of the attributes, hence in order to make comparisons in variance we need to ensure they are in the same scale using Normalization techniques.\n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### 2.3 Investigate Pairs of Variables\n\n#### Correlation Plot Function"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# function for correlation plot\nrange_color <- c('#69091e', '#e37f65', 'white', '#58fc9a', '#036e2e')\n## colorRamp() returns a function which takes as an argument a number\n## on [0,1] and returns a color in the gradient in colorRange\nColor_RampFunc <- colorRamp(range_color)\n\ncor_panel <- function(w, z, ...) {\n    correlation <- cor(w, z)\n\n    col <- rgb(Color_RampFunc((1 + correlation) / 2 ) / 255 )\n\n    ## square it to avoid visual bias due to \"area vs diameter\"\n    radius <- sqrt(abs(correlation))\n    radians <- seq(0, 2*pi, len = 50) # 50 is arbitrary\n    x <- radius * cos(radians)\n    y <- radius * sin(radians)\n    ## make them full loops\n    x <- c(x, tail(x,n=1))\n    y <- c(y, tail(y,n=1))\n\n    par(new=TRUE)\n    plot(0, type='n', xlim=c(-1,1), ylim=c(-1,1), axes=FALSE, asp=1)\n    polygon(x, y, border=col, col=col)\n}",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# to exclude x and y from being plotted in correlation plot\npairs(fire_data[c(-1,-2)], upper.panel = cor_panel) \n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "\nThe correlation matrix shows:\n- FFMC, DMC, DC , ISI and temp have correlation to each other - in particular both DMC and DC have a stronger positive correlation to each other.\n- There is a strong positive correlation between month and DC.\n- There is very little correlation between day, rain and area with the other variables.\n- RH is negatively correlated to temp and FFMC - there is a stronger negative correlation between temp and RH.\n- There is a weak negative correlation between wind and temperature as well as between wind and DC."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Correlation coefficient "
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# function for correlation matrix\npanel_func <- function(x, y, z, ...) {\n    panel.levelplot(x,y,z,...)\n    panel.text(x, y, round(z, 2))\n}\n#Define the color scheme\ncols = colorRampPalette(c(\"blue\",\"green\"))\n#Plot the correlation matrix.\nlevelplot(cor(fire_data[c(-1,-2,-3,-4)]), col.regions = cols(100), main = \"Correlation between variables\",\n          scales = list(x = list(rot = 90)), panel = panel_func)\n\n# plot size\noptions(repr.plot.width=9, repr.plot.height=8)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The higher positive correlations are between:\n- DC and DMC\n\nThe only significant negative correlation is between RH and temp."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Investigating relationship between month and area burnt "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# barplot for count of months \nmonth_count <- ggplot(fire_data, aes(x = month)) + geom_bar(stat = \"count\", fill = 'darkmagenta') + \nlabs(title=\"Figure A: Total count of months\",x =\"Month\", y = \"Total count per month\")\n# barplot for total area burnt for every month \ntotal_area <- ggplot(as.data.frame(fire_data), aes(month,area, fill = month)) + geom_col(position = 'dodge')+ \nlabs(title=\"Figure B: Total area burnt for every month \",x =\"Month\", y = \"Total Area\")\n\n# plotting figures side by side\ncowplot :: plot_grid(month_count,total_area)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Based on figure A, we can see that the data has the highest count for August, September and March. We would expect that the total area burnt would be higher for the months with the higher count. However, surprisingly, in figure B, the highest total area is in September, followed by August and July. These months could possibly have outlier values which affect the total area burnt."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Investigating relationship between days and area burnt "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# barplot for count of days\nday_count <- ggplot(fire_data, aes(x = day)) + geom_bar(stat = \"count\", fill = 'darkmagenta') + \nlabs(title=\"Figure A: Total count of days\",x =\"Days\", y = \"Total count per day\")\n# barplot for total area burnt for days respectively  \ntotal_area <- ggplot(as.data.frame(fire_data), aes(day,area, fill = day)) + geom_col(position = 'dodge')+ \nlabs(title=\"Figure B: Total area burnt based on days \",x =\"Days\", y = \"Total Area\")\n\n# plotting figures side by side\ncowplot :: plot_grid(day_count,total_area)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Based on figure A, we can see that the data has the highest count for sudays, fridays and satursdays. We would expect that the total area burnt would be higher for days with the higher count. However, surprisingly, in figure B, the highest total area is on saturdays, thursdays and mondays. These days could possibly have outlier values which affect the total area burnt."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### 2.4 Insights derived from Exploratory Data Analysis\n\n- **High skewness for predictor and response variable**: There seem to be high skewness for 'area' (response variable) and 'rain'(predictor variable) with data mainly skewed towards 0 (right skewed). This creates a problem as the tail region may act as an outlier which will affect the model's performance if not normalized.\n\n- **Low correlation between predictors and response variable**: There are low correlation between the predictor and response variable. However, we can see that several of the attributes are correlated, with a high correlation between month and DC, as well as DMC and DC. In addition, several of the predictor variables like FFMC, DMC, DC , ISI and temp seem to be correlated,therefore it make sense to apply some sort of feature selection. \n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 3. Model Development<a class=\"anchor\" id=\"sec_3\"></a>"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "For this subsection, we are implementing the transformations required in order to improve the accuracy of the models. Then, the feature selection is done to investigate which features are essential and are incorporated to the built model. "
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "####  Initial model with all features "
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "A model with all the features is developed to compare the models with transformed model and lesser features."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# creating function to calculate mean squared error \nmse_model <- function(model)\n    mean(model$residuals^2)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# ensure results are repeatable\nset.seed(5)\n# linear model\nlmfit3 = lm(area~., data = fire_data)\nsummary(lmfit3)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "**From the summary of the model**:\n\n- The adjusted R-squared ($R^2$) value of -0.006905 indicates this model does not explain the variation in area.\n\n- The F-statistic 0.8689 has a p-value < 0.6581 - so cannot reject the null hypothesis (the model explains nothing) - the model is not useful\n\n- The p-values for the coefficients show that only DMC and DC are significant at the 0.05 level.\n\nSome transformation is needed to improve the model which will be done later."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "mse_model(lmfit3) # MSE for model with all the features which are not transformed",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "As shown above, we can see that MSE is high which indicates that the data values are dispersed widely around its mean and that the data is skewed. Therefore, we need to build a model with lower MSE."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Using plot() function to produce diagnostic plots of the linear regression fit\n\nThe purpose of this is to check the following assumptions:\n\n- Constant variance\n\n- Linearity\n\n- Normality"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# plotting residual vs fitted, scale - location, normal q-q and residual vs leverage plots\noptions(repr.plot.width=9, repr.plot.height=8) \npar(mfcol=c(2,2))  \nplot(lmfit3)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The following conclusions are derived from the plots above:\n\n\n* The **residual vs fitted plot**: This plot is used to check linear assumption. This is to indicate whether residuals have non linear patterns. The first plot above shows that there could be a non-linear relationship between area and all the predictors, as there is an obvious pattern in this plot given that the residuals are not scattered evenly. \n\n* The normal **Q-Q plot**: In the case of linear regression analysis, we assume that residual is normally distributed with constant variance and mean equal to zero. The normal Q-Q plot shows if residuals are normally distributed. In this case we can see that the residuals are lined well on the straight dashed line, therefore the residuals are most likely distributed normally.\n\n* The **scale-location plot**: This plot is used to check the assumption of equal variance by showing if residuals are spread equally along the ranges of predictors. The scale-location plot shows that the residuals appear randomly spread.\n\n\n* The **residual-leverage plot**: This plot is used to identify influential data sample. As observed, the forth plot shows outliers such as 480,416 and 239. We note that point 239 and 416 is close to Cook's distance of 0.5. However, these outlier points are not outside of the Cook's distance lines. Therefore there are no influential cases observed.\n\n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### 3.1 Model Transformation\nData transformation is done in order to generate symmetric distribution instead of the original skewed distribution to make it is easier to interpret and generate inferences. The relationship between variables are clearer when we re-express the variables, especially when converting non-linear relationship between variables to linear ones. Below transformations are done to both categorical and numerical variables."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### 3.1.1. Categorical variable transformation\n##### Creating dummies for categorical variables\nDummies are created for categorical variables namely month and day from the dataset to indicate the absence or presence of some categorical effect that may be expected to shift the outcome."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# new dataframe for dummy\nfire.new <- dummy.data.frame(fire_data,sep = \".\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# creating dummy variable for months\ndummy(fire_data$month, sep = \".\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# creating dummy variable for days\ndummy(fire_data$day, sep = \".\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# incorporating dummy variables to fire_data1 dataset\nfire_data1 <- dummy.data.frame(names = c(\"month\",\"day\"), fire_data,sep = \".\") \nfire_data1",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### 3.1.2. Numeric Variable Transformation "
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "##### Logarithmic transformation\n\nSkewed data makes it difficult to check as most of the observations are constricted in a small part of the range of the data. Hence, logarithmic transformation is performed on 'area' and 'rain' to adjust the data distribution to make it less skewed. Given that both these features have zero values which will create an error value, log(x+1) transformation is used to avoid the errors.\n\n"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# check skewness for area \nskewness(fire_data1$area) ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "From the result above, we can see that the skewness of area is high, therefore, we will need to perform a log transformation. The skewness can also be observed with the QQ and histogram plot below. "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "## qq plot for area\nqqnorm(fire_data1[,13], main = \"\")\nqqline(fire_data1[,13], col = 2,lwd=2,lty=2, main = \"\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# histogram plot for area to observe the distribution \nhist(fire_data1$area, xlab=\"Area\", main = \"\",col=\"darkmagenta\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "As shown by the 2 plots above, we can see that the area variable is highly skewed to the right highly skewed towards 0.0. Therefore, a log transformation is performed in the next step."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# log transformation for area\nfire_data1$area <- log(fire_data1$area +1) ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "qqnorm(fire_data1$area, main = \"\")\nqqline(fire_data1$area, col = 2, lwd=2,lty=2)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "hist(fire_data1$area, xlab=\"Area\", main = \"\",col=\"darkmagenta\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "As shown by the 2 plots above, it is observed that the QQ plot and histogram are more normal after transformation compared to before transformation. "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# skewness value after transformation\nskewness(fire_data1$area)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "It is also observed that the skewness for area is recorded lower at 1.21078001224549 after transformation compared to 12.7724826585002\nwhich was recorded before the transformation.\n\nNext, we are exploring the skewness of the rain."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# skewness of rain \nskewness(fire_data1$rain)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "From the result above, we can see that the skewness of rain is high, therefore, we will need to perform a log transformation. The skewness can also be observed with the QQ and histogram plot below. "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "\nqqnorm(fire_data1[,12], main = \"\"); qqline(fire_data1[,12], col = 2,lwd=2,lty=2, main = \"\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "hist(fire_data1$rain, xlab=\"Rain\", main = \"\", col=\"darkmagenta\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "As shown by the 2 plots above, we can see that the rain variable is highly skewed to the right highly skewed towards 0.0. Therefore, a log transformation is performed in the next step."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "fire_data1$rain <- log(fire_data1$rain +1) # log transformation for area",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "qqnorm(fire_data1$rain, main = \"\")\nqqline(fire_data1$rain, col = 2, lwd=2,lty=2)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "hist(fire_data1$rain, xlab=\"Rain\", main = \"\", col=\"darkmagenta\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "As shown by the 2 plots above, it is observed that the QQ plot and histogram are still highly skewed after transformation. We will check with the skewness function to observe as to whhether the skewness decreased after transformation."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "skewness(fire_data1$rain)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "It is observed that the skewness for area is recorded lower at 14.0908918136066 after transformation compared to 19.7015038029727 which was recorded before the transformation, however it is still high.\n\nNext, we observe whether the transformation of area and rain as well as adding of dummy variables have contributed to the improvement in model.   "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# ensure results are repeatable\nset.seed(5)\n# linear model after transformation\nlmwithtrans = lm(area~., data = fire_data1)\nsummary(lmwithtrans)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "**From the summary of the model**:\n\n- The adjusted R-squared ($R^2$) of 0.02354 indicates that this model explains 2.35% of the variation in area. This is better than the previous R- squared of -0.006905 which did not explain the variation in area.\n\n- The F-statistic 1.461 has a p-value 0.06487 - so cannot reject the null hypothesis (the model explains nothing) - the model is not useful\n\n- The p-values for the coefficients show that Y, month, DMC and temp are significant at the 0.05 level.\n\nGiven an improvement in the adjusted R-squared value from -0.006905 to 0.02354  as well as a lower p value from \n0.6581 to 0.06487 from the previous transformation,  we can indicate that the model is performing better after applying the log transformation on area and rain.\n"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "mse_model(lmwithtrans) # checking mse after log transformation on area and rain",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "As shown above, we can see that MSE is low and much lower compared to before transformation (3859.07245262511) which indicates that the data values are dispersed closely around its mean and that the data is not skewed."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Best normalize function\n\nBest normalize function is performed to normalize transformations and selects the best on the basis of the Pearson P test statistic for normality. The tranformation which has the lowest P calculated on the transformed data is selected. "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# performing best normalize function on FFMC variable\nfire_FFMCnorm <- bestNormalize(fire_data1$FFMC)\nfire_FFMCnorm",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Based on the transformation above, we can see that the estimated normality statistic for the OrderNorm transformation is close to one, so we know it is performing quite well. It is also performing better than all of the other transformations."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# performing best normalize function on DMC variable\nfire_DMCnorm <- bestNormalize(fire_data1$DMC)\nfire_DMCnorm",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Based on the transformation above, we can see that the estimated normality statistic for the OrderNorm transformation is the closest to one, so we know it is performing quite well. It is also performing better than all of the other transformations."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# performing best normalize function on DC variable\nfire_DCnorm <- bestNormalize(fire_data1$DC)\nfire_DCnorm",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Based on the transformation above, we can see that the estimated normality statistic for the OrderNorm transformation is the closest to one, so we know it is performing quite well. We also note that it is also performing better in comparison to the other transformations."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# performing best normalize function on ISI variable\nfire_ISInorm <- bestNormalize(fire_data1$ISI)\nfire_ISInorm",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Based on the transformation above, we can see that the estimated normality statistic for the OrderNorm transformation is the closest to one, so we know it is performing quite well. We also note that it is also performing better in comparison to the other transformations."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# performing best normalize function on temp variable\nfire_tempnorm <- bestNormalize(fire_data1$temp)\nfire_tempnorm",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Based on the transformation above, we can see that the estimated normality statistic for the Yeo-Johnson transformation is the closest to one, so we know it is performing quite well. We also note that it is also performing better in comparison to the other transformations."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# performing best normalize function on RH variable\nfire_RHnorm <- bestNormalize(fire_data1$RH)\nfire_RHnorm",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Based on the transformation above, we can see that the estimated normality statistic for the OrderNorm transformation is the closest to one, so we know it is performing quite well. We also note that it is also performing better in comparison to the other transformations."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# performing best normalize function on wind variable\nfire_windnorm <- bestNormalize(fire_data1$wind)\nfire_windnorm",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Based on the transformation above, we can see that the estimated normality statistic for the OrderNorm transformation is the closest to one, so we know it is performing quite well. We also note that it is also performing better in comparison to the other transformations."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# performing best normalize function on rain variable\nfire_rainnorm <- bestNormalize(fire_data1$rain)\nfire_rainnorm",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "As shown above, none of the normalizing transformations performed well according to the normality statistics. The frequency of ties in this case makes it very difficult to find a normalizing transformation. However, orderNorm is chosen as it has the lowest estimated P/df statistic."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# performing best normalize function on area variable\nfire_areanorm <- bestNormalize(fire_data1$area)\nfire_areanorm",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Based on the transformation above, we can see that the estimated normality statistic for the no transformation method is the closest to one, so we know it is performing quite well. It is also performing better than all of the other transformations. This indicates that we've performed the relevant trasnformation of log (area + 1) in the earlier trasnformation.\n\nNext, we observe as to whether the transformations performed with the bestNormalize function has improved the distribution of the variables with the histogram plots.  "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# layout of graphs\npar(mfrow = c(3, 2))\n#plotting the histogram for original FFMC \nMASS::truehist(fire_data1$FFMC, col=\"darkmagenta\")\n#plotting the histogram for FFMC after transformation \nMASS::truehist(fire_FFMCnorm$x.t, col=\"darkmagenta\")\n#plotting the histogram for original DMC\nMASS::truehist(fire_data$DMC, col=\"darkmagenta\")\n#plotting the histogram for DMC after transformation\nMASS::truehist(fire_DMCnorm$x.t, col=\"darkmagenta\")\n#plotting the histogram for original DC\nMASS::truehist(fire_data1$DC, col=\"darkmagenta\")\n#plotting the histogram for DC after transformation\nMASS::truehist(fire_DCnorm$x.t, col=\"darkmagenta\")\n#plotting the histogram for original ISI\nMASS::truehist(fire_data1$ISI, col=\"darkmagenta\")\n#plotting the histogram for ISI after transformation\nMASS::truehist(fire_ISInorm$x.t, col=\"darkmagenta\")\n#plotting the histogram for original temp\nMASS::truehist(fire_data1$temp, col=\"darkmagenta\")\n#plotting the histogram for temp after transformation\nMASS::truehist(fire_tempnorm$x.t,col=\"darkmagenta\")\n#plotting the histogram for original RH\nMASS::truehist(fire_data1$RH, col=\"darkmagenta\")\n#plotting the histogram for RH after transformation\nMASS::truehist(fire_RHnorm$x.t, col=\"darkmagenta\")\n#plotting the histogram for original wind\nMASS::truehist(fire_data1$wind,col=\"darkmagenta\")\n#plotting the histogram for wind after transformation\nMASS::truehist(fire_windnorm$x.t,col=\"darkmagenta\")\n#plotting the histogram for original rain\nMASS::truehist(fire_data1$rain,col=\"darkmagenta\")\n#plotting the histogram for rain after transformation\nMASS::truehist(fire_rainnorm$x.t,col=\"darkmagenta\")\n#plotting the histogram for original area\nMASS::truehist(fire_data1$area,col=\"darkmagenta\")\n#plotting the histogram for area after transformation\nMASS::truehist(fire_areanorm$x.t,col=\"darkmagenta\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "As shown above, we can see that there are improvements in the distributions for FFMC, DMC, DC, ISI, temp, RH and wind as the distributions look more normalized than before. The distribution for rain and area remained the same.\n\nGiven the improvement in the distribution, we would like to discover whether the transformed variables explains the variation in area better."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# creating new column for transformed FFMC\nfire_data1$FFMC.t <- fire_FFMCnorm$x.t\n# creating new column for transformed DMC\nfire_data1$DMC.t <- fire_DMCnorm$x.t\n# creating new column for transformed DC\nfire_data1$DC.t <- fire_DCnorm$x.t\n# creating new column for transformed ISI\nfire_data1$ISI.t <- fire_ISInorm$x.t\n# creating new column for transformed temp\nfire_data1$temp.t <- fire_tempnorm$x.t\n# creating new column for transformed RH\nfire_data1$RH.t <- fire_RHnorm$x.t\n# creating new column for transformed wind\nfire_data1$wind.t <- fire_windnorm$x.t\n# creating new column for transformed rain\nfire_data1$rain.t <- fire_rainnorm$x.t\n# creating new column for transformed area\nfire_data1$area.t <- fire_areanorm$x.t",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# checking colummn names for dataset\ncolnames(fire_data1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# updating the dataset by removing the non transformed variables\nfire_data1 <- fire_data1[,-c(22:30)] # minus non transformed variables ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# ensure results are repeatable\nset.seed(5)\n# create linear model with transformed variables\nlinear_trans <- lm(area.t~.,data = fire_data1)\nsummary(linear_trans)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "**From the summary of the model**:\n\n- The adjusted R-squared ($R^2$) of 0.02652 indicates that this model explains 2.65% of the variation in area. This is better than the previous R- squared of 0.02354 (with just log transformation of area and rain).\n\n- The F-statistic 1.521 has a p-value 0.04677 - so we can reject the null hypothesis (the model explains nothing) with significance level of 0.05 - the model is useful.\n\n- The p-values for the coefficients show that DMC,DC, temp, month and wind  are significant at the 0.05 level.\n\nGiven an improvement in the adjusted R-squared value from 0.02354 to 0.02652 as well as a lower p value from 0.06487 to 0.04677 from the previous transformation,  we can indicate that the model is performing better after applying the bestnormalize function.\n"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "mse_model(linear_trans)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "As shown above, we can see that MSE is low and much lower compared to just transformation of log area and rain (1.80617079683761) which indicates that the data values are dispersed closely around its mean and that the data is not skewed.\n\n\nLet's observe the residuals vs fitted plot, scale-location plot, normal q-q plot and residuals vs leverage plot to visualise the effect of transformation. "
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true
      },
      "cell_type": "code",
      "source": "# getting residual vs fitted plot, scale- location plot, normal q-q plot, residual vs leverage plot\noptions(repr.plot.width=9, repr.plot.height=8) \npar(mfcol=c(2,2))  \nplot(linear_trans)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The following conclusions are derived from the plots above:\n\n* The **residual vs fitted plot**: This plot is used to check linear assumption. This is to indicate whether residuals have non linear patterns. The first plot above shows that there could be a non-linear relationship between area and all the predictors, as there is an obvious pattern in this plot given that the residuals are not scattered evenly. This is still similiar to before transformation as residuals are still not scattered evenly. \n\n* The normal **Q-Q plot**: In the case of linear regression analysis, we assume that residual is normally distributed with constant variance and mean equal to zero. The normal Q-Q plot shows if residuals are normally distributed. In this case we can see that the residuals are lined well on the straight dashed line, therefore the residuals are most likely distributed normally. This is more normalised compared to before the transformation. \n\n* The **scale-location plot**: This plot is used to check the assumption of equal variance by showing if residuals are spread equally along the ranges of predictors. The scale-location plot shows that the residuals appear randomly spread. This is similar to before the transformation where residuals are still randomly spread.\n\n* The **residual-leverage plot**: This plot is used to identify influential data sample. As observed, the forth plot shows outliers such as 472,305 and 500. We note that point 500 is outside the Cook's distance lines. Therefore point 500 is an influential point and needs to be removed as it could lead to measurement error."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Below is a plot with a close up look of the index with influential points from the data. "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#calculating distance of points\ncook.sd <- cooks.distance(linear_trans)\n# Plot the Cook's Distance using the traditional 4/n criterion\nsamplesize <- nrow(fire_data1)\n# plot cook's distance\nplot(cook.sd, pch=\"*\", cex=2, main=\"Influential Points by Cooks distance\")  \n # add cutoff line\nabline(h = 4/samplesize, col=\"blue\") \n # add labels\ntext(x=1:length(cook.sd)+1, y=cook.sd, labels=ifelse(cook.sd>4/samplesize, names(cook.sd),\"\"), col=\"red\") ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "As shown in the plot above, we can see that the obvious influential points are at index 500, 305 and 472. These points will be removed below."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Removing the top 3 outliers\ntop_x_outlier <- 3\n\n#getting top 3 outlier points index\ninfluential <- as.numeric(names(sort(cook.sd, decreasing = TRUE)[1:top_x_outlier]))\n\n# removing top 3 outlier points from dataset\nfire_data2 <- fire_data1[-influential,]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# ensure results are repeatable\nset.seed(5)\n# building linear model from new dataset with outliers removed\ntransformed_model <- lm(area.t ~ FFMC.t + DMC.t +  DC.t + ISI.t +temp.t + RH.t + wind.t + rain.t + X + \n           Y + month.jan + month.feb + month.mar + month.apr + month.may + month.jun + month.jul + \n           month.aug + month.sep + month.oct + month.nov + month.dec + day.mon + day.tue + day.wed +\n           day.thu + day.fri + day.sat + day.sun , data= fire_data2)\n\nsummary(transformed_model)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "**From the summary of the model**:\n\n- The adjusted R-squared ($R^2$) of 0.03291 indicates that this model explains 3.23% of the variation in area.This is better than the previous R- squared of 0.02504.\n\n- The F-statistic 1.671 has a p-value 0.02106 - so we cannot reject the null hypothesis (the model explains nothing) with significance level of 0.05. This model is useful.\n\n- The p-values for the coefficients show that month, DMC, temp, wind, rain and X are significant at the 0.05 level.\n\nGiven an improvement in the adjusted R-squared value from 0.02652 to 0.03291 as well as a lower p value from 0.04677 to 0.02106 prior to removing the influential point,  we can indicate that the model is performing better after removing the influential point.\n\nMSE of the model is calculated below to investigate the distribution and skewness of the model."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "mse_model(transformed_model)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "As shown above, we can see that MSE is low and much lower compared to prior removal of outliers (0.920755890560974) which indicates that the data values are dispersed closely around its mean and that the data is not skewed.\n\nGiven that transformation is done and has improved the MSE of the model, we can move on to feature selection.\n\n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### 3.2 Feature Selection \n\nFeature selection is done by performing hard selection which consist of best subset and hybrid selection. Thereafter, cross validation is then performed on the hard selections to choose the optimal number of predictors required for the model to be optimised.\n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### 3.2.1 Performing Hybrid Subset Selection \n\nHybrid selection is a combination of both forward and backward selection in which the model adds and removes features one by one to reach the optimal model."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# ensure results are repeatable\nset.seed(5)\n#performing hybrid selection on data \nregfit.both = regsubsets(area.t ~ .,data = fire_data2, method = 'seqrep')\n#getting summary results for hybrid selection\nreg.summary.both <- summary(regfit.both)\nreg.summary.both",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The above reports the best set of variables for each model size with asterisk indicating that a given variable is included in the corresponding model. Based on the analysis above, it is difficult to know which models to choose for our predictive analysis. Therefore, Cp, BIC, adjusted R square and residual sum of square (RSS) are used as indicators to help obtain the best model selection.\n\n\n**Cp** acts as a penalty which tries to minimize overfitting which is created by our model during training the model. Penalty increases as the number of predictors increases. The model with lowest Cp is the best model.\n\n**BIC** is similiar to Cp. The model with least value is the best model as it indicates a low test error. \n\n**Adjusted R Square** measures the correct variables and voice variable in the variable. A higher adjusted r square is preferable as it  has more correct variables and lesser noise variable into it.\n\n**Residual Sum of Square (RSS)** is used to measure the amount of variance in the data that is not explained by the model. A lower RSS is preferred as it indicates a lower variance and error. \n\nA set of plots are generated to visualise the best overall model based on Cp, BIC, adjusted r squared and RSS as shown below:\n"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "par(mfrow = c(2, 2))\n#plotting cp for hybrid selection\nplot(reg.summary.both$cp, xlab = \"Number of variables\", ylab = \"Cp\", type = \"l\")\n#plotting minimum point of cp for hybrid selection\npoints(which.min(reg.summary.both$cp), reg.summary.both$cp[which.min(reg.summary.both$cp)], col = \"red\", cex = 2, pch = 20)\n#plotting bic for hybrid selection\nplot(reg.summary.both$bic, xlab = \"Number of variables\", ylab = \"BIC\", type = \"l\")\n#plotting minimum point of bic for hybrid selection\npoints(which.min(reg.summary.both$bic), reg.summary.both$bic[which.min(reg.summary.both$bic)], col = \"red\", cex = 2, pch = 20)\n#plotting adjusted r squared for hybrid selection\nplot(reg.summary.both$adjr2, xlab = \"Number of variables\", ylab = \"Adjusted R Squared\", type = \"l\")\n#plotting maximum point of adjusted r square for hybrid selection\npoints(which.max(reg.summary.both$adjr2), reg.summary.both$adjr2[which.max(reg.summary.both$adjr2)], col = \"red\", cex = 2, pch = 20)\n\nplot(reg.summary.both$rss, xlab = \"Number of variables\", ylab = \"RSS\", type = \"l\")\nmtext(\"Plots of Cp, BIC, Adjusted R Squared and RSS for hybrid stepwise selection\", side = 3, line = -2, outer = TRUE)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "As shown in the plots above, we can see that based on Cp,adjusted r squared, the best model is estimated to have 9 predictor variables. For BIC on the other hand, it estimated that the best model have 1 predictor variable.\n\nThe best model according to each adjusted r squared, Cp and BIC for hybrid stepwise selection are extracted to confirm and are shown as below:  "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# plotting dataframe for best model based on maximum adjusted r square, minimum cp and minimum bic.\ndata.frame(\nadj.r2 = which.max(reg.summary.both$adjr2),\n                  cp = which.min(reg.summary.both$cp),\nbic = which.min(reg.summary.both$bic))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We can see from the above that based on adjusted r square and cp the best model is the one with 9 predictor variables. However, using the BIC criteria, we should go for the model with 1 variable. Given that we have different \"best\" models depending on which metrics we consider. Therefore, a more vigorous approach is to select a model based on the prediction error computed on a new test data using k-fold cross validation techniques."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# helper function to allow easy access to formula of models returned by the function regsubsets()\nget_model_formula <- function(id,object) {\nmodels <- summary(object)$which[id,-1]\nform <- as.formula(object$call[[2]])\noutcome <- all.vars(form)[1]\npredictors <- names(which(models == TRUE))\npredictors <- paste(predictors, collapse=\"+\")\nas.formula(paste0(outcome,\"~\",predictors))\n     }",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# helper function to get cross validation error for a given model\nget_cv_error <- function(model.formula, data){\n    set.seed(1)\n    train.control <- trainControl(method = \"cv\", number = 9)\n    cv <- train(model.formula, data = data, method = 'lm', trControl = train.control)\n    cv$results$RMSE\n}",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We will use the defined helper function above to compute the prediction error for the different best models returned by the regsubsets() function  "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# computing cross validation error\nmodel.ids <- 1:9\ncv.errors <- map(model.ids, get_model_formula,regfit.both) %>%\nmap(get_cv_error, data = fire_data2) %>%\nunlist()\ncv.errors",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Cross validation errors are shown above based on each of the respective models which have different variable numbers. The which.min() function is performed to indicate the minimum cross validation error from the models as shown below:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# selecting the best model that minimizes the cross validation error\nwhich.min(cv.errors)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "As shown above, we can see that the model with 9 variables is the best model. This is so as it has the lowest prediction error.\n\nThe regression coefficients of this model are shown as below:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "coef(regfit.both,9)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Based on coefficient above, we can see that the 9 variables that are important are X, month.feb, month.oct, day.tue, FFMC,temp, rain, month.dec and day.sun. \n\nNext, we explore the optimal model from best subset selection to see if it's similiar to the hybrid selection above.\n\n#### 3.2.2. Performing best subset selection"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# ensure results are repeatable\nset.seed(5)\n#performing best subset selection on data \nregfit.full = regsubsets(area.t~.,data = fire_data2)\nreg.summary.full <- summary(regfit.full)\nreg.summary.full",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The above reports the best set of variables for each model size with asterisk indicating that a given variable is included in the corresponding model. Based on the analysis above, it is difficult to know which models to choose for our predictive analysis. Therefore, Cp, BIC, adjusted R square and residual sum of square (RSS) are used as indicators to help obtain the best model selection.\n\n\n**Cp** acts as a penalty which tries to minimize overfitting which is created by our model during training the model. Penalty increases as the number of predictors increases. The model with lowest Cp is the best model.\n\n**BIC** is similiar to Cp. The model with least value is the best model as it indicates a low test error. \n\n**Adjusted R Square** measures the correct variables and voice variable in the variable. A higher adjusted r square is preferable as it  has more correct variables and lesser noise variable into it.\n\n**Residual Sum of Square (RSS)** is used to measure the amount of variance in the data that is not explained by the model. A lower RSS is preferred as it indicates a lower variance and error. \n\nA set of plots are generated to visualise the best overall model based on Cp, BIC, adjusted r squared and RSS as shown below:\n\n"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "par(mfrow = c(2, 2))\nplot(reg.summary.full$cp, xlab = \"Number of variables\", ylab = \"Cp\", type = \"l\")\npoints(which.min(reg.summary.full$cp), reg.summary.full$cp[which.min(reg.summary.full$cp)], col = \"red\", cex = 2, pch = 20)\nplot(reg.summary.full$bic, xlab = \"Number of variables\", ylab = \"BIC\", type = \"l\")\npoints(which.min(reg.summary.full$bic), reg.summary.full$bic[which.min(reg.summary.full$bic)], col = \"red\", cex = 2, pch = 20)\nplot(reg.summary.full$adjr2, xlab = \"Number of variables\", ylab = \"Adjusted R Square\", type = \"l\")\npoints(which.max(reg.summary.full$adjr2), reg.summary.full$adjr2[which.max(reg.summary.full$adjr2)], col = \"red\", cex = 2, pch = 20)\nplot(reg.summary.full$rss, xlab = \"Number of variables\", ylab = \"RSS\", type = \"l\")\nmtext(\"Plots of Cp, BIC, adjusted r sqaure and RSS for best subset selection\", side = 3, line = -2, outer = TRUE)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "As shown in the plots above, we can see that based on Cp,adjusted r squared and RSS, the best model is estimated to have 9 predictor variables. For BIC on the other hand, it estimated that the best model have 1 predictor variable.\n\nThe best model according to each adjusted r squared, Cp and BIC for best subset selection are extracted to confirm and are shown as below:  "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# plotting dataframe for best model based on maximum adjusted r square, minimum cp and minimum bic.\ndata.frame(\nadj.r2 = which.max(reg.summary.full$adjr2),\n                  cp = which.min(reg.summary.full$cp),\nbic = which.min(reg.summary.full$bic))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We can see from the above that based on adjusted r square and cp the best model is the one with 9 predictor variables. However, using the BIC criteria, we should go for the model with 1 variable. Given that we have different \"best\" models depending on which metrics we consider. Therefore, a more vigorous approach is to select a model based on the prediction error computed on a new test data using k-fold cross validation techniques.\n\nWe will use the defined helper function above to compute the prediction error for the different best models returned by the regsubsets() function below:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "model.ids <- 1:9\ncv.errors1 <- map(model.ids, get_model_formula,regfit.full) %>%\nmap(get_cv_error, data = fire_data2) %>%\nunlist()\ncv.errors1",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Cross validation errors are shown above based on each of the respective models which have different variable numbers. The which.min() function is performed to indicate the minimum cross validation error from the models as shown below:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "which.min(cv.errors1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "As shown above, we can see that the model with 9 variables is the best model as it has lowest prediction error. This is similiar to the number of variables for the best model selected from hybrid subset selection.\n\nThe regression coefficients of this model are shown as below:"
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true
      },
      "cell_type": "code",
      "source": "coef(regfit.full,9)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Based on coefficient above, we can see that the 9 variables that are important are X, month.feb, month.oct, day.tue, FFMC,temp, rain, month.dec and day.sun. These are the same variables as the hybrid selection."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# storing important variables obtained from cross validation for both hybrid and best subset selection to dataframe named imp_features\nimp_features <- fire_data1[,c(\"X\", \"month.feb\", \"month.oct\", \"day.tue\",\"FFMC.t\",\"temp.t\",\"rain.t\",\"month.dec\",\"day.sun\",\"area.t\")]\nhead(imp_features)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Splitting dataset into train and test\n\nThe data is split into 80% ratio for training and 20% for testing. The model is trained to with the training dataset and the predictions are tested on the testing dataset. Thereafer, the mean squared error (MSE) is then computed to obtain the accuracy of the model. "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# ensure results are repeatable\nset.seed(5) \n# splitting data with 80 to 20 ratio\nsample = sample.split(imp_features, SplitRatio = .80)\n# making 80% of the data to train data\ntrain_firedata = subset(imp_features, sample == TRUE)\n# making 20% of the data to test data\ntest_firedata  = subset(imp_features, sample == FALSE)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### 3.3 Model 1- Linear model\n\nBelow a linear model is built based upon the important features obtained from subset selection. "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# ensure results are repeatable\nset.seed(5)\n# linear model based on important features obtained from feature selection\nlmlate = lm(area.t~.,  data = imp_features)\nsummary(lmlate)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "**From the summary of the model**:\n\n- The adjusted R-squared ($R^2$) of 0.02182 indicates that this model explains 2.18% of the variation in area. This is lower than the previous R- squared of 0.03291 prior to feature selection. The lower adjusted r square could be due to a reduction in the features. However, the model built with lesser features compared to with full features would be more computationally efficient and have higher interpretebility.  \n\n- The F-statistic 2.279 has a p-value 0.01646 - so we cannot reject the null hypothesis (the model explains nothing) with significance level of 0.05. This model is useful. We note that the p value is lower compared to the p value of the linear model before feature selection of 0.02106. This indicates and improvement in the significance of the model.\n\n- The p-values for the coefficients show that temp and month are significant at the 0.05 level.\n"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# getting mse value for model\ncat(\"The MSE for the linear model with variables from feature selection is:\",mse_model(lmlate))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Building linear model based on train dataset"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# ensure results are repeatable\nset.seed(5)\n# building linear model from train dataset\nlinear_model <- lm(area.t ~. , data = train_firedata)\nsummary(linear_model)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "**From the summary of the model**:\n\n- The adjusted R-squared ($R^2$) of 0.01419 indicates that this model explains 1.42% of the variation in area.\n\n- The F-statistic 1.66 has a p-value 0.09657 - so we cannot reject the null hypothesis (the model explains nothing) with significance level of 0.05. This model is useful.\n\n- The p-values for the coefficients show that temp and month are significant at the 0.05 level.\n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Predicting on test data:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# using train dataset to predict test dataset\npredictions_linear <- linear_model %>% predict(test_firedata)\n\n# storing predictions to compare_lm dataframe for comparison\ncompare_lm <- as.data.frame(predictions_linear)\n\n# selecting target value\nactual_area <- dplyr:: select(test_firedata,area.t)\n\n# merging predicted values with actual values\ncompare_lm <- cbind(compare_lm, actual_area)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# printing first few records of actual vs predicted\nhead(compare_lm)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# obtaining r squared value for model\ncat(\"The R squared value for the linear model is:\",R2(predictions_linear, test_firedata$area.t))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# obtaining MSE for model\nMSE_linear <- mse(predictions_linear, test_firedata$area.t)\ncat(\"The mean squared error (MSE) for the linear model is\",MSE_linear)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# obtaining RMSE for model\nRMSE_linear <- RMSE(predictions_linear, test_firedata$area.t)\ncat(\"The root mean square error (RMSE) for the linear model is\",RMSE_linear)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### 3.4 Model 2 - XGBoost \n\n- The second model is built on the extreme gradient boosting algorithm, also known as XGBoost.\n- The dataset is the final subset of the selected features which was used to implement linear regression. MSE is used as a benchmark to compare the accuracy of the models, in which a lower MSE indicates that the model provides better predictions.\n- This model uses an ensemble technique called boosting whereby new models are added to correct the errors made by existing models.\n- Gradient boosting is an approach where new models are created that predict the residuals or errors of prior models and then added together to make the final prediction. A gradient descent algorithm is utilized to minimize the loss when adding new models."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Creating training and test dataframe for XGBoost Model"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# creating train dataframe without area column\ntrainm <- train_firedata[-10]\n# creating train data frame with just area column\ntrain_label <- train_firedata[,\"area.t\"]\n# converting training data set to matrix format to use the xgboost algorithm\ntrain_matrix <- xgb.DMatrix(data = as.matrix(trainm), label = train_label)\n\n\n# creating test dataframe without area column\ntestm <- test_firedata[-10]\n# creating test dataframe with just area column\ntest_label <- test_firedata[,\"area.t\"]\n# converting test data set to matrix format to use the xgboost algorithm\ntest_matrix <- xgb.DMatrix(data = as.matrix(testm), label = test_label)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Builidng XGBoost model based on train dataset"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# setting up paramaters to be used by xgboost model\nxgb_params <- list(\"objective\" = \"reg:linear\", # for linear regression\n                   \"eval_metric\" = \"rmse\") # using rmse for evaluation metric\n\n# creating watchlist to input into XGBoost model, to see how much error exist in each iteration\nwatchlist <- list(train = train_matrix , test = test_matrix)\n\n# creating XGBoost model for 100 iterations for train model\nbst_model <- xgb.train(params = xgb_params, data = train_matrix,nrounds = 100, watchlist = watchlist)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "As shown above, we can see the train and test RMSE for the XGBoost model for 100 iterations."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Training and test error plot for XGBoost"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "e <- data.frame(bst_model$evaluation_log)\n# plotting training data's rmse for each iteration\nplot(e$iter, e$train_rmse, col = \"blue\", xlab = \"Iteration Number\",ylab = \"RMSE for train data\") \n# plotting test data's rmse for each iteration\nlines(e$iter, e$test_rmse, col = 'red')\n\nmtext(\"Plot of Iteration Number vs RMSE for train data-XGBoost\", side = 3, line = -2, outer = TRUE)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "As shown above, we can see that initially the RMSE for test data decreased, however it quickly increases. This is so as the reduction in error for the training data is causing significant overfitting. The plot for test data indicates that the right model is not found yet.\n\nWe can obtain the minimum value for the test RMSE from the plot above below by using the min() function. The iteration number for the minimum value of test RMSE is also investigated."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# getting minimum value for test rmse\nmin(e$test_rmse)\n# getting iteration of minimum rmse value\ne[e$test_rmse == 1.030477, ]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "As shown above, we can see that iteration number 4 is where the minimum value of test RMSE is obtained for the training and test plot."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# adding on lower eta on XGB Boost train model\nbst_model <- xgb.train(params = xgb_params, data = train_matrix,nrounds = 100, watchlist = watchlist, eta = 0.1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The ETA variable is added on to the model to improve the learning rate of the model. The changes are visualised in the training and test error plot below."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "e <- data.frame(bst_model$evaluation_log)\n# plotting training data's rmse for each iteration\nplot(e$iter, e$train_rmse, col = \"blue\", xlab = \"Iteration Number\", ylab = \"RMSE for train data\")\n# plotting test data's rmse for each iteration\nlines(e$iter, e$test_rmse, col = 'red')\n\nmtext(\"Plot of Iteration Number vs RMSE for train data -XGBoost\", side = 3, line = -2, outer = TRUE)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "As shown above, we can see an improvement in the RMSE for test data as it did not increase as quickly as before. The reduction in error for the training in data is also more gradual now.\n\n\nThe minimum value for the test RMSE from the plot above below is obtained by using the min() function. The iteration number for the minimum value of test RMSE is also further investigated."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# getting minimum value for test rmse\nmin(e$test_rmse)\n\n# getting iteration of minimum rmse value\ne[e$test_rmse == 1.027956, ]\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We can see an improvement in RMSE from  1.030477 to 1.027956 with  a lower eta (learning rate). Iteration number 21 is where the minimum value of test RMSE is obtained for the updated training and test plot.\n\nThis would be incorporated into the XGBoost train model as nrounds =21 (to indicate 21 iterations) in order to obtain a minimum error for test data."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# performing XGB boost based on iteration number 21 given low rmse to get minimum error for test data\nbst_model <- xgb.train(params = xgb_params, data = train_matrix,nrounds = 21, watchlist = watchlist, eta = 0.1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "e <- data.frame(bst_model$evaluation_log)\n# plotting training data's rmse for each iteration\nplot(e$iter, e$train_rmse, col = \"blue\", xlab = \"Iteration Number\" ,ylab = \"RMSE for train data\" )\n# plotting test data's rmse for each iteration\nlines(e$iter, e$test_rmse, col = 'red')\n\nmtext(\"Plot of Iteration Number vs RMSE for train data -XGBoost\", side = 3, line = -2, outer = TRUE)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "As shown above, we can see an improvement in the RMSE for test data as it did not increase as before and is declining gradually. We can also see that the reduction in error for the training in data is still persistent.\n\nGiven a reduction in the RMSE, we can now obtain the important features for the data. "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# geting feature importance from importance data table\nimp <- xgb.importance(colnames(train_matrix), bst_model)\nprint(imp)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Based on the table above, we can see that the temperature variable is the most important variable followed by FFMC and X. This is based on the relative number of observations and number of times the feature occurs in the trees of the model as calculated by cover and frequency from the importance data table.\n\nWe can visualise the ranking of the important variables below as well."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# plotting feature importance variables\nxgb.plot.importance(imp)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "As shown above, temperature variable is the most important variable followed by FFMC and X."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Predicting on test data:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# prediction on test data\npredicted_xg <- predict(bst_model, newdata = test_matrix)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#storing predictions to compare_xg dataframe for comparison\ncompare_xg <- as.data.frame(predicted_xg)\n# selecting target value\nactual_area <- test_label\n# merging predicted values with actual values\ncompare_xg <- cbind(compare_xg, actual_area)\n# getting first few rows of predicted values and actual values comparison\nhead(compare_xg)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# obtaining r squared value for model\ncat(\"The R squared value for the XGBoost model is:\",R2(predicted_xg, test_label))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# obtaining MSE for model\nMSE_xg <- mse(predicted_xg, test_label)\ncat(\"The mean squared error (MSE) for the XGBoost model is\",MSE_xg)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# obtaining RMSE for model\nRMSE_xg <- RMSE(predicted_xg, test_label)\ncat(\"The root mean square error (RMSE) for the XGBoost model is\",RMSE_xg)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Reason for Choosing XGBoost:\n\n- Tuning of parameters in XGBoost allows improvement in accuracy of prediction and reduces the mean square errors.\n- XGBoost penalizes complex models with both ridge and lasso regularization to prevent overfitting of data.\n- XGBoost utilizes the power of parallel processing which makes the computation of the model fast.\n- Boosting in the model makes use of trees with lesser splits therefore making them more efficient and with better prediction accuracy."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### 3.5 Model 3 - XG Boost lasso"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "- This model is similiar to the initial XGBoost model performed for model 2 which uses ensemble technique to correct the errors made by existing models. However,this model is enhanced as we are adding on the lasso parameter to the model. \n- The dataset for this model differs from the first and second model as well as it contains initial variables without any feature selection. The dataset for model 1 and 2 is the final subset of the selected features.\n- The lasso parameter in this model performs both variable selection and regularization in order to enhance the prediction accuracy and interpretability of the statistical model it produces."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Creating training and test dataframe for XGBoost Lasso Model"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# ensure results are repeatable\nset.seed(5) \n# splitting original data before feature selection to 80 to 20 ratio  \nsample_xg = sample.split(fire_data2, SplitRatio = .80)\n# making 80% of the data to train data\ntrain_firedata_xg = subset(fire_data2, sample_xg == TRUE)\n# making 20% of the data to test data\ntest_firedata_xg  = subset(fire_data2, sample_xg == FALSE)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# creating train dataframe without area column\ntrainm_xg <- train_firedata_xg[-30]\n# creating train data frame with just area column\ntrain_label_xg <- train_firedata_xg[,\"area.t\"]\n# converting training data set to matrix format to use the xgboost algorithm\ntrain_matrix_xg <- xgb.DMatrix(data = as.matrix(trainm_xg), label = train_label_xg)\n\n# creating test dataframe without area column\ntestm_xg <- test_firedata_xg[-30]\n# creating test data frame with just area column\ntest_label_xg <- test_firedata_xg[,\"area.t\"]\n# converting test data set to matrix format to use the xgboost algorithm\ntest_matrix_xg <- xgb.DMatrix(data = as.matrix(testm_xg), label = test_label_xg)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Builidng XGBoost Lasso model based on train dataset"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# setting up paramaters to be used by xgboost model\nxgb_params <- list(\"objective\" = \"reg:linear\",# for linear regression\n                   \"eval_metric\" = \"rmse\", # using rmse for evaluation metric\n                   \"alpha\" = 1) # apply lasso regression\n\n# creating watchlist to input into XGBoost model, to see how much error exist in each iteration\nwatchlist_xg <- list(train = train_matrix_xg , test = test_matrix_xg)\n\n# creating XGBoost model for 100 iterations\nbst_model_xg <- xgb.train(params = xgb_params, data = train_matrix_xg,nrounds = 100, watchlist = watchlist_xg)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "As shown above, we can see the train and test RMSE for the XGBoost model for 100 iterations."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Training and test error plot for XGBoost Lasso"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "e_xg <- data.frame(bst_model_xg$evaluation_log)\n# plotting training data's rmse for each iteration\nplot(e_xg$iter, e_xg$train_rmse, col = \"blue\",xlab = \"Iteration Number\" ,ylab = \"RMSE for train data\")\n# plotting test data's rmse for each iteration\nlines(e_xg$iter, e_xg$test_rmse, col = 'red')\nmtext(\"Plot of Iteration Number vs RMSE for train data -XGBoost\", side = 3, line = -2, outer = TRUE)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "As shown above, we can't really see the plot for RMSE for test data. However, we can observe that the RMSE for training data has been declining till roughly around iteration 40. Thereafter, the RMSE remains constant till iteration 100 for training data.\n\nWe can obtain the minimum value for the test RMSE from the plot above below by using the min() function. The iteration number for the minimum value of test RMSE is also investigated."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# getting minimum value for test rmse\nmin(e_xg$test_rmse)\n# getting iteration of minimum rmse value\ne_xg[e_xg$test_rmse == 1.030912, ]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "As shown above, we can see that iteration number 4 is where the minimum value of 1.030912 for test RMSE is obtained for the training and test plot."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# adding on lower eta \nbst_model_xg <- xgb.train(params = xgb_params, data = train_matrix_xg,nrounds = 100, watchlist = watchlist_xg, eta = 0.1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The ETA variable is added on to the model to improve the learning rate of the model. The changes are visualised in the training and test error plot below."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "e_xg <- data.frame(bst_model_xg$evaluation_log)\n# plotting training data's rmse for each iteration\nplot(e_xg$iter, e_xg$train_rmse, col = \"blue\",xlab = \"Iteration Number\" ,ylab = \"RMSE for train data\")\n# plotting test data's rmse for each iteration\nlines(e_xg$iter, e_xg$test_rmse, col = 'red')\nmtext(\"Plot of Iteration Number vs RMSE for train data -XGBoost\", side = 3, line = -2, outer = TRUE)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "As shown above, we can see now see the RMSE for test data which gradually declines before iteration 20 and then increases. The reduction in error for the training in data is also more gradual now and is not stagnant as before.\n\nThe minimum value for the test RMSE from the plot above below is obtained by using the min() function. The iteration number for the minimum value of test RMSE is also further investigated."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "min(e_xg$test_rmse)\ne_xg[e_xg$test_rmse == 1.005882, ]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We can see an improvement in RMSE from 1.030912 to 1.005882 with  a lower eta (learning rate). Iteration number 13 is where the minimum value of test RMSE is obtained for the updated training and test plot.\n\nThis would be incorporated into the XGBoost train model as nrounds =13 (to indicate 13 iterations) in order to obtain a minimum error for test data."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# performing XGB boost based on iteration number 13 given low rmse to get minimum error for test data\nbst_model_xg <- xgb.train(params = xgb_params, data = train_matrix_xg,nrounds = 13, watchlist = watchlist_xg, eta = 0.1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "As shown above, we can see the train and test RMSE for the XGBoost model for 13 iterations.\n    \nThe RMSE for both training and test data are visualised as below."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "e_xg <- data.frame(bst_model_xg$evaluation_log)\nplot(e_xg$iter, e_xg$train_rmse, col = \"blue\", xlab = \"Iteration Number\" ,ylab = \"RMSE for train data\")\nlines(e_xg$iter, e_xg$test_rmse, col = 'red')\nmtext(\"Plot of Iteration Number vs RMSE for train data -XGBoost\", side = 3, line = -2, outer = TRUE)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "As shown above, we can see an improvement in the RMSE for test data as it did not increase as before and is declining gradually. We can also see that the reduction in error for the training in data is more spread up.\n\nGiven a reduction in the RMSE from , we can now obtain the important features for the data. \n"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# getting important variables \nimp_var <- xgb.importance(colnames(train_matrix_xg), bst_model_xg)\nprint(imp_var)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Based on the table above, we can see that the temperature variable is the most important variable followed by wind and DMC. This is based on the relative number of observations and number of times the feature occurs in the trees of the model as calculated by cover and frequency from the importance data table.\n\nWe can visualise the ranking of the important variables below as well."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#plotting important variables\nxgb.plot.importance(imp_var)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "As shown above, temperature variable is the most important variable followed by FFMC and X."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Predicting on test data:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# prediction on test data\npredicted_xg2 <- predict(bst_model_xg, newdata = test_matrix_xg)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#storing predictions to compare_xg2 dataframe for comparison\ncompare_xg2 <- as.data.frame(predicted_xg2)\n# selecting target value\nactual_area_xg <- test_label_xg\n# merging predicted values with actual values\ncompare_xg2 <- cbind(compare_xg2, actual_area_xg)\n# getting first few rows of predicted values and actual values comparison\nhead(compare_xg2)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# obtaining r squared value for model\ncat(\"The R squared value for the XGBoost Lasso model is:\",R2(predicted_xg2, test_label_xg))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# obtaining MSE for model\nMSE_xg2 <- mse(predicted_xg2, test_label_xg)\ncat(\"The mean squared error (MSE) for the XGBoost Lasso model is\",MSE_xg2)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# obtaining RMSE for model\nRMSE_xg2 <- RMSE(predicted_xg2, test_label_xg)\ncat(\"The root mean square error (RMSE) for the XGBoost Lasso model is\",RMSE_xg2)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "#### Reason for Choosing XGBoost Lasso:\n\n- Able to avoid overfitting and narrow down the features of the data in a more accurate manner with the use of lasso parameter from XGBoost.\n- Tuning of parameters in XGBoost allows improvement in accuracy of prediction and reduces the mean square errors.\n- The model offer efficient estimates of the test error without incurring the cost of repeated model training associated with cross-validation. "
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 4. Model Comparison<a class=\"anchor\" id=\"sec_4\"></a>"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "A scatter plot of the predicted vs actual values of the area is displayed to analyse which model has the highest prediction accuracy."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### 4.1 Model 1 - Linear Model:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "cat(\"Correlation between predicted and actual values for linear model: \",cor(compare_lm$predictions_linear,compare_lm$area.t) )\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "ggplot(compare_lm, aes(x=predictions_linear, y=area.t)) +\n  geom_point()+\n  geom_smooth(method=lm)+\n    ggtitle(\"Predicted vs test data for Model 1: Linear Model\") +\n      xlab(\"Predicted values for area\") +\n      ylab(\"Actual values for area \")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### 4.2 Model 2 - XG Boost"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "cat(\"Correlation between predicted and actual values for XGBoost Model: \", cor(compare_xg$predicted_xg,compare_xg$actual_area))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "ggplot(compare_xg, aes(x=predicted_xg, y=actual_area)) +\n  geom_point()+\n  geom_smooth(method=lm)+\n    ggtitle(\"Predicted vs test data for Model 2: XGBoost Model\") +\n      xlab(\"Predicted values for area\") +\n      ylab(\"Actual values for area \")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### 4.3 Model 3 - XGBoost Lasso"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "cat(\"Correlation between predicted and actual values for XGBoost Lasso Model: \",cor(compare_xg2$predicted_xg2,compare_xg2$actual_area_xg))\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "ggplot(compare_xg2, aes(x=predicted_xg2, y=actual_area_xg)) +\n  geom_point()+\n  geom_smooth(method=lm)+\n    ggtitle(\"Predicted vs test data for Model 3: XGBoost Lasso Model\") +\n      xlab(\"Predicted values for area\") +\n      ylab(\"Actual values for area\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Comparing between the 3 models, it is observed that the fit is better for Model 1 in comparison to model 2 and 3. There is a more linear relationship between the actual and predicted values for model 1 which was built on linear regression. The correlation coefficient between the actual and predicted values are relatively low for the models, with linear regression having the highest correlation value of 0.2158215, followed by XGBoost Lasso with value of 0.08270509 and XGBoost with value of   0.01967348. However, we note that correlation doesnt mean causation. The correlation co-efficient was tabulated to investigate how closely the actual and predicted values are related to each other."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "### 4.4 MSE and RMSE of models\n\n- MSE measures the mean of the squares of the errors which is the difference between the predicted values and the actual values and squaring them. The mean of this value provides us an indication of the error in the model in terms of its prediction capability. A lower MSE indicates that the model is performing better in terms of prediction, however a very low MSE could sometimes lead to over fitting. \n\n- RMSE on the other hand measures the standard deviation of the residuals which indicates how spread out these residuals are. A lower RMSE value indicate a better fit, however like MSE a very low MSE value could lead to over fitting of the data.\n\nThe MSE and RMSE calculated after prediction are performed on test data set and is provided as below"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "cat(\"The mean square error(MSE) of linear model is :\", MSE_linear)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "cat(\"The root mean square error(RMSE) of linear model is :\", RMSE_linear)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "cat(\"The mean square error(MSE) of XGBoost model is :\", MSE_xg)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "cat(\"The root mean square error(RMSE) of XGBoost Model is :\", RMSE_xg)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "cat(\"The mean square error(MSE) of XGBoost Lasso model is :\", MSE_xg2)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "cat(\"The root mean square error(RMSE) of XGBoost Lasso Model is :\", RMSE_xg2)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Based on the values above, we can see that the linear model has the lowest RMSE and MSE amongst the other models. In addition to the better fit of the model based on the plots,  we can conclude that the linear model is the better model in comparison to the other two models.\n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 5. Variable Identification and Explanation <a class=\"anchor\" id=\"sec_5\"></a>"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "The variables used for linear model provided it with the lowest RMSE. Therefore, they are selected as the most important variables."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "cat(\"Name of important variables:\",colnames(imp_features)[1:8])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The chosen subset of attributes that might have a significant impact on the prediction of area are shown above. There were initially 12 predictor variables. Based on the hybrid selection, we've narrowed down our feature selection to X, month.feb, month.oct, day.tue, FFMC, temp, rain and month.dec. It is noted that the month variable in particular February,October and December is when the area of forest is affected most. For the day variable, tuesday is important variable among the other days. Given that month and day are individual variable, the total number of important features are 6 variables namely, X, month,day,FFMC, temp and rain."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### 5.1 Month"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Among all the variables in the final subset, one of the influencing attribute is month. In particular, the month of december. This can be observed in the linear regression model developed and as shown below. The p value for this feature is extremely low and is below 0.05. This could possibly due to the humid weather in the month of December which could affect the spread of the fire in the area."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# ensure results are repeatable\nset.seed(5)\n# linear model based on important features obtained from feature selection\nlmlate = lm(area.t~.,  data = imp_features)\nsummary(lmlate)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### 5.2 Temperature \nTemperature is also another important variable as reflected in both the models XGBoost and XGBoost Lasso as it was ranked highest for  important variables as shown below. It is also observed in the linear regression model above that the p value for this feature is extremely low and is below 0.05. This could possibly be due to the fact that temperature does affect the humidity and could lead to bushfire. "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# importance plot for XGBoost\nxgb.plot.importance(imp)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# importance plot for XGBoost Lasso\nxgb.plot.importance(imp_var)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### 5.3 FFMC\n\nFFMC is the abbreviation for Fine Fuel Moisture Code. FFMC is one of the important features and as shown in the correlation plot below it is correlated to temperature and month which are also the most important variables in feature selection. Therefore, it could possibly have a greater impact on the response variable due to its interactions with the other 2 important variables."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "pairs(fire_data[c(-1,-2)], upper.panel = cor_panel) ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### 5.4  X\n\nX is the coordinate of the area. It is observed that this variable is ranked third in terms of importance in the XGBoost and XGBoost Lasso model."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 6. Conclusion <a class=\"anchor\" id=\"sec_6\"></a>"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "- The feature selection methods were utilized to identify the optimum number of features which can explain the changes in the target variable.\n- EDA was performed to obtain insights as to which key factors should be considered while selecting features for the model.\n- The reduced subset of features was used to build 2 different models which are linear regression and XGBoost. The full subset of features on the other hand was applied on XGBoost Lasso.\n- It was observed that R-squared and MSE for a linear model is higher in comparison to the other 2 models.\n- The final set of features was 6 variables which have higher significance in comparison to the other features."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 7. References <a class=\"anchor\" id=\"sec_7\"></a>"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "https://subscription.packtpub.com/book/big_data_and_business_intelligence/9781783989065/1/ch01lvl1sec21/creating-dummies-for-categorical-variables"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "https://discuss.analyticsvidhya.com/t/methods-to-deal-with-zero-values-while-performing-log-transformation-of-variable/2431/2"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "https://towardsdatascience.com/catalog-of-variable-transformations-to-make-your-model-works-better-7b506bf80b97"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "https://cran.r-project.org/web/packages/bestNormalize/vignettes/bestNormalize.html"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "https://books.google.com.au/books?id=745QDwAAQBAJ&pg=PA79&lpg=PA79&dq=is+bic+and+adjr2+same+usually+for+model+selection&source=bl&ots=5DQvAQXZOp&sig=ACfU3U3OYIpgDMG9Nllgf6sTb5DR9SDR9Q&hl=en&sa=X&ved=2ahUKEwjnqNK17aHpAhUTzDgGHW-6D2k4ChDoATACegQIBxAB#v=onepage&q=is%20bic%20and%20adjr2%20same%20usually%20for%20model%20selection&f=false"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "https://stats.stackexchange.com/questions/164099/removing-outliers-based-on-cooks-distance-in-r-language"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "https://www.youtube.com/watch?v=woVTNwRrFHE"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "https://www.hackerearth.com/practice/machine-learning/machine-learning-algorithms/beginners-tutorial-on-xgboost-parameter-tuning-r/tutorial/"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "https://medium.com/analytics-vidhya/model-selection-cp-aic-bic-and-adjusted-r2-6a0af25945b6"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "https://machinelearningmastery.com/gentle-introduction-xgboost-applied-machine-learning/"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "r",
      "display_name": "R",
      "language": "R"
    },
    "language": "fsharp",
    "language_info": {
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "3.5.3",
      "file_extension": ".r",
      "codemirror_mode": "r"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}